{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SIN.06023 L'Apprentissage Automatique\n",
    "\n",
    "### Semestre de printemps 2025\n",
    "\n",
    "### Matthew Vowels\n",
    "(PhD Eng., PhD Appl. Math, MS, MSc, BMus (hons))\n",
    "\n",
    "Slides available at www.github.com/matthewvowels1/SIN06023\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/logo.png\" alt=\"drawing\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calendrier des cours\n",
    "\n",
    "Semaine 1: Révision des concepts clés de l'algèbre linéaire, de la théorie des probabilités et de l'optimisation\n",
    "\n",
    "Semaine 2: Algorithmes d'apprentissage, capacité et biais-variance, et 'maximum likelihood estimation'\n",
    "\n",
    "Semaine 3: Répartition et validation train/test, k-fold, optimisation des hyperparamètres\n",
    "\n",
    "Semaine 4: Apprentissage supervisé et non-supervisé\n",
    "\n",
    "Semaine 5: Machines vectorielles de support\n",
    "\n",
    "Semaine 6: Arbres de décision et forêts aléatoires\n",
    "\n",
    "Semaine 7: Réseaux de neurone: Rétropropagation, règle de chaîne et optimisation stochastique\n",
    "\n",
    "Semaine 8: Réseaux de neurones\n",
    "\n",
    "Semaine 9: Réseaux convolutifs\n",
    "\n",
    "**Semaine 10:  Biais, équité, et justice dans l'apprentissage automatique**\n",
    "\n",
    "Semaine 11: Apprentissage automatique explicable (importances, SHAP, LIME) et calibration\n",
    "\n",
    "Semaine 12 : Récapitulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTK34uxMjMYL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Semaine 10: Biais, équité, et justice dans l'apprentissage automatique\n",
    "\n",
    "\n",
    "\n",
    "**Comme toujours, vous devez accéder au contenu du notebook Jupyter depuis le référentiel et l'ouvrir dans Google Colab (ou localement si vous le souhaitez).**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources\n",
    "\n",
    "\n",
    "Solon Barocas, Moritz Hardt, Arvind Narayanan. Fairness and Machine Learning: Limitations and Opportunities\n",
    "https://fairmlbook.org\n",
    "\n",
    "Meredith Broussard. Artificial Unintelligence: How Computers Misunderstand the World\n",
    "\n",
    "Keynotes/Tutoriels par Joy Boulamwini, Kate Crawford, Meredith Whitaker et d'autres.\n",
    "\n",
    "Le contenu de cette conférence est inspiré de la discussion de Moritz Hardt des biais :\n",
    "https://www.youtube.com/watch?v=Igq_S_7IfOU \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Qu’est-ce que c'est qu'un biais ?\n",
    "\n",
    "\n",
    "Le terme 'biais' se réfère généralement à une erreur systématique ou une injustice dans la manière dont un modèle d'apprentissage automatique traite les données, ce qui reflète et perpétue souvent les inégalités sociales existantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leçons clés pour aujourd'hui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "-  L’utilisation (peut-être bien intentionnée) des algorithmes sans prise de conscience des problèmes conduit à des problèmes d’iniquité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "- « Nous n’utilisons pas cette variable » n’est pas un argument.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "- Il n’existe pas de solution universelle au problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "- Il est important de réfléchir à l'application avant le déploiement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/bias1.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/bias2.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/bias3.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/bias4.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Il existe une interprétation du « droit à l’explication »"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- La loi évolue et évolue en réponse aux éventuels problèmes exacerbés par l’IA et l'apprentissage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Alors, qu’est-ce qu’une *discrimination injustifiée* dans l’apprentissage automatique ?\n",
    "\n",
    "Deux types :\n",
    "\n",
    "- Non-pertinence pratique (orientation sexuelle dans les décisions d'emploi ou les recommandations d'emploi)\n",
    "\n",
    "- Non-pertinence morale – plus compliquée (statut de handicap ou grossesse dans les décisions d'embauche et impact, par exemple, sur le coût pour l'employeur)\n",
    "\n",
    "\n",
    "Notez qu’on peut avoir un algorithme avec un comportement équitable qui n’est pas juste !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notez également qu'il existe diverses fonctionnalités sensibles (aux États-Unis par exemple, ce sont des classes protégées) :\n",
    "\n",
    "- Race\n",
    "- Genre\n",
    "- Grossesse\n",
    "- Religion\n",
    "- Statut familial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Anciennes cartes « ligne rouge » permettant aux agents de prêt de décider où prêter et où ne pas prêter - ce n'est plus légal aux États-Unis\n",
    "\n",
    "<img src=\"redline.png\" alt=\"drawing\" width=\"800\" align=\"center\"/>\n",
    "https://www.youtube.com/watch?v=Igq_S_7IfOU Moritz Hardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "La loi essaie de suivre les progrès...\n",
    "\n",
    "- Règlement général sur la protection des données (RGPD) : article 22 : accorde aux individus le droit de ne pas être soumis à des décisions basées uniquement sur une prise de décision automatisée, ce qui implique un besoin de transparence et d'explicabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Concevez un système capable d'évaluer s'il vaut la peine de livrer le jour même dans une région particulière ou non.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$${f}: \\mathbf{X} \\rightarrow y$$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/prediction_task.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exemple issu du monde réel...\n",
    "\n",
    "Couverture de livraison Amazon le jour même\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/amazonMap.png\" alt=\"drawing\" width=\"1000\" align=\"center\"/>\n",
    "https://www.bloomberg.com/graphics/2016-amazon-same-day/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exemple issu du monde réel...\n",
    "\n",
    "Couverture de livraison Amazon le jour même\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/amazonMapZoom.png\" alt=\"drawing\" width=\"600\" align=\"center\"/>\n",
    "https://www.bloomberg.com/graphics/2016-amazon-same-day/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Leçon 1: L’utilisation (peut-être bien intentionnée) des algorithmes sans prise de conscience des problèmes conduit à des problèmes d’iniquité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Une grande question à laquelle sont confrontés (surtout) les ingénieurs aux États-Unis :\n",
    "\n",
    "- Devraient-ils collecter l’origine ethnique comme variable ?\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/prediction_task.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "L'origine ethnique est codée indirectement dans les autres variables (une variable latente), peut-être via des mécanismes sociaux inéquitables que nous ne voulons pas perpétuer\n",
    "\n",
    "\n",
    "Donc, même sans l’utiliser comme variable, cela peut toujours être un problème.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/prediction_task_latent.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De plus, si nous ne collectons pas l'origine ethnique, nous n’avons aucune possibilité d’évaluer si notre modèle prend indirectement des décisions en l’utilisant.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/prediction_task_latent.png\" alt=\"drawing\" width=\"900\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Leçon 2: Donc « Nous n’utilisons pas cette variable » n’est pas un argument.\n",
    "\n",
    "### En anglais on dirait que 'there is no fairness without awareness'  (il n'y a pas de justice sans conscience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Alors, comment décidons-nous d’inclure ou non une variable ?\n",
    "\n",
    "\n",
    "Deux types de non-pertinence (dans le choix d'un employé, par. ex.).\n",
    "\n",
    "Si une variable appartient à l’une de ces deux catégories, ce n’est pas une bonne idée de l’utiliser comme prédicteur. Cependant, cela peut quand même être important à considérer !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1) Non-pertinence pratique (orientation sexuelle dans les décisions d'emploi ou les recommandations d'emploi)\n",
    "\n",
    "\n",
    "\n",
    "2) Non-pertinence morale – plus compliquée (statut de handicap ou grossesse dans les décisions d'embauche et impact, par exemple, sur le coût pour l'employeur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notez que certaines variables sont importants à prendre en compte pour d’autres raisons.\n",
    "\n",
    "Par exemple, l'origine ethnique peut être un prédicteur justifiable 'pratique' dans certains processus de décision médicale en raison de certains liens génétiques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alors, comment pouvons-nous évaluer et tester l’équité ?\n",
    "\n",
    "- Critères d'équité dans la classification\n",
    "\n",
    "(Modélisation causale et explicabilité la semaine prochaine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les deux critères populaires\n",
    "\n",
    "1) Taux positif égal:  un nombre égal de cas « acceptés » dans tous les groupes\n",
    "\n",
    "$$p(\\hat{Y}=1 | G=a) = p(\\hat{Y}=1 | G=b)$$\n",
    "\n",
    "Motivation : \"Tous les groupes ont un droit égal à l'acceptation.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les deux critères populaires\n",
    "\n",
    "2) Égalisation des taux d’erreur: nombre de faux positifs et de négatifs égal dans tous les groupes \n",
    " \n",
    "$$p(\\hat{Y}=1|Y=0, G=a) = p(\\hat{Y}=1|Y=0, G=b)$$\n",
    "\n",
    "$$p(\\hat{Y}=0|Y=1, G=a) = p(\\hat{Y}=0|Y=1, G=b)$$\n",
    "\n",
    "Motivation : \"Qui supporte le coût d'une mauvaise classification ? Historiquement, les taux d'erreur plus élevés se produisent davantage dans les groupes marginalisés. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 1 **Taux positif égal**\n",
    "\n",
    "Pour le decision $\\hat{Y}$, l'appartenance au groupe $G$:\n",
    "\n",
    "\n",
    "$$p(\\hat{Y}=1 | G=a) = p(\\hat{Y}=1 | G=b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "def calculate_equal_positive_rate(predictions: np.ndarray, groups: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the equal positive rate criterion for a decision classifier,\n",
    "    considering only the group membership.\n",
    "\n",
    "    :param predictions: A NumPy array containing binary predictions from the classifier.\n",
    "    :param groups: A NumPy array indicating the group membership of each prediction.\n",
    "    :return: A dictionary with the positive rate for each group.\n",
    "    \"\"\"\n",
    "    unique_groups = np.unique(groups)\n",
    "    positive_rates: Dict[str, float] = {}\n",
    "\n",
    "    for group in unique_groups:\n",
    "        # Mask for the current group\n",
    "        mask = (groups == group)\n",
    "\n",
    "        # Calculate positive rate for the group\n",
    "        positive_rate = predictions[mask].mean()\n",
    "        positive_rates[group] = positive_rate\n",
    "\n",
    "    return positive_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example group assignment: ['B' 'A' 'A' 'B' 'A']\n",
      "Example predictions: [1 0 1 0 0]\n",
      "Per-group positive rate: {'A': 0.5272727272727272, 'B': 0.4888888888888889}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Générer quelques exemples de données\n",
    "y_true = np.random.randint(0, 2, size=N)\n",
    "\n",
    "groups = np.random.choice(['A', 'B'], size=N)\n",
    "print('Example group assignment:',groups[:5])\n",
    "\n",
    "y_pred = np.random.randint(0, 2, size=N)  #  Au lieu de cela, écoutez vos prédictions réelles\n",
    "print('Example predictions:', y_pred[:5])\n",
    "\n",
    "result = calculate_equal_positive_rate(y_pred, groups)  # nous n'utilisons pas les vraies étiquettes\n",
    "print('Per-group positive rate:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 1 **Taux positif égal** : faiblesses !\n",
    "\n",
    "\n",
    "On peut avoir un nombre élevé de vrais positifs dans un groupe et un nombre élevé de faux positifs dans un autre, et remplir le critère de taux de positivité égale.\n",
    "\n",
    "Il existe des solutions dégénérées qui satisfont au critère."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 2 **Égalisation des taux d’erreur**\n",
    "\n",
    "\n",
    "Assurer un taux de faux positifs égal:\n",
    "\n",
    "$$p(\\hat{Y}=1|Y=0, G=a) = p(\\hat{Y}=1|Y=0, G=b)$$\n",
    "\n",
    "\n",
    "et garantir un taux de faux négatifs égal:\n",
    "\n",
    "$$p(\\hat{Y}=0|Y=1, G=a) = p(\\hat{Y}=0|Y=1, G=b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_false_rates(y_true: np.ndarray, y_pred: np.ndarray, groups: np.ndarray) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the false positive and false negative rates for each group.\n",
    "\n",
    "    :param y_true: A NumPy array containing the true labels.\n",
    "    :param y_pred: A NumPy array containing the predicted labels.\n",
    "    :param groups: A NumPy array indicating the group membership of each label.\n",
    "    :return: A dictionary with the false positive and false negative rates for each group.\n",
    "    \"\"\"\n",
    "    unique_groups = np.unique(groups)\n",
    "    fp_rates: Dict[str, float] = {}\n",
    "    fn_rates: Dict[str, float] = {}\n",
    "\n",
    "    for group in unique_groups:\n",
    "        mask = (groups == group)\n",
    "\n",
    "        # False positives: where true label is 0 but predicted label is 1\n",
    "        false_positives = np.sum((y_true[mask] == 0) & (y_pred[mask] == 1))\n",
    "\n",
    "        # False negatives: where true label is 1 but predicted label is 0\n",
    "        false_negatives = np.sum((y_true[mask] == 1) & (y_pred[mask] == 0))\n",
    "\n",
    "        # Total negatives and positives \n",
    "        total_negatives = np.sum(y_true[mask] == 0)\n",
    "        total_positives = np.sum(y_true[mask] == 1)\n",
    "\n",
    "        fp_rate = false_positives / total_negatives if total_negatives > 0 else 0\n",
    "        fn_rate = false_negatives / total_positives if total_positives > 0 else 0\n",
    "\n",
    "        fp_rates[group] = fp_rate\n",
    "        fn_rates[group] = fn_rate\n",
    "\n",
    "    return fp_rates, fn_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rates: {'A': 0.375, 'B': 0.6}\n",
      "False negative rates: {'A': 0.3548387096774194, 'B': 0.6}\n"
     ]
    }
   ],
   "source": [
    "fp_rates, fn_rates = calculate_false_rates(y_true, y_pred, groups)\n",
    "print('False positive rates:', fp_rates)\n",
    "print('False negative rates:', fn_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 2 **Égalisation des taux d’erreur** : faiblesses !\n",
    "\n",
    "Ce critère ne peut être évalué qu'<après> avoir les vraies données - c'est un critère 'post-hoc'. \n",
    "\n",
    "Une telle évaluation peut arriver « trop tard ».\n",
    "\n",
    "\n",
    "Parfois, nous ne pouvons jamais l'évaluer... (par exemple, l'embauche)\n",
    "\n",
    "\n",
    "Cela ne nous aide pas non plus à éviter les solutions dégénérées..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 3 **Calibration** \n",
    "\n",
    "Pour une fonction de score $R(\\mathbf{X})$ qui pourrait simplement être une estimation de $\\mathbb{E}[Y|\\mathbf{X}]$, un score $R$ est calibré si :\n",
    "\n",
    "$$p(Y=1 | R=r) = r$$\n",
    "\n",
    "Nous pouvons calibrer par groupe :\n",
    "\n",
    "$$p(Y=y | R=r, G=a) = r$$\n",
    "\n",
    "Nous voulons donc que notre score se comporte comme une probabilité au sein de chaque groupe et signifie donc ce qu'il est censé signifier.\n",
    "\n",
    "Cela découle de $Y \\perp\\!\\!\\!\\!\\perp G | R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 3 **Calibration** \n",
    "\n",
    "En mots : si mon objectif est de prédire $Y$, après avoir observé le score $R$ il n'est pas nécessaire de connaître l'appartenance au groupe. Un r = 0,8 signifie 0,8 quel que soit le groupe.\n",
    "\n",
    "Si un modèle est calibré, cela signifie que le score reflète fidèlement la probabilité du véritable résultat $Y$, quelle que soit l'appartenance au groupe $G=a$ ou $G=b$ ou autre. Il garantit la fiabilité et la « fiabilité » du classificateur entre les groupes.\n",
    "\n",
    "Par exemple. r = 0,8 signifie un taux d'insuffisance cardiaque de 80 % en moyenne par rapport aux personnes qui reçoivent un score de 0,8 - leur appartenance à un groupe ne change rien à cela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 3 **Calibration** : faiblesses !\n",
    "\n",
    "Cela ne change rien à la pérennisation des inégalités liées aux coûts réels (par exemple grossesses ou handicaps de productivité). \n",
    "\n",
    "Calibration ne résout pas le problème de pertinence morale dont nous avons parlé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Faiblesses des deux\n",
    "\n",
    "Ils sont incompatibles!\n",
    "\n",
    "Exemple simple..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On peut utiliser ces critères pour détecter des problèmes, mais ils ne vous indiquent pas quelle devrait être la solution. En effet, ils sont également tous deux incompatibles !\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/incompatibility.png\" alt=\"drawing\" width=\"700\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Changez le contexte mais gardez les chiffres les mêmes...\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/employment.jpg\" alt=\"drawing\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "En moyenne, les hommes seront moins qualifiés, ce qui entraînera un pire bilan pour ce groupe, créant ainsi un nouveau déséquilibre lié au groupe. Mais... nous pourrions ainsi bénéficier d'une meilleure diversité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Leçon 3: Il n’existe pas de solution universelle au problème.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Autres avertissements :\n",
    "\n",
    "Le respect des critères d'équité à l'aide de l'apprentissage automatique peut souvent conduire à des « solutions paresseuses » et à des problèmes d'équité des **sous**groupes. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/subgroup.png\" alt=\"drawing\" width=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Des solutions globales nécessitaient une compréhension détaillée des problèmes sociétaux, moraux et équitables sous-jacents liés au domaine.\n",
    "\n",
    "### Par conséquent, les ingénieurs devraient s'adresser à des experts du domaine !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Considérez** « Défaut de comparaître devant le tribunal ».\n",
    "\n",
    "**Une approche en cours de promotion** : prédire l'absence de comparution et de détention si le risque est élevé (cela peut durer longtemps - cela est dévastateur pour les familles et le soutien social, et coûteux).\n",
    "\n",
    "**Alternative** : mettre en œuvre des mesures pour atténuer les problèmes. Reconnaître que les personnes ne se présentent pas au tribunal en raison de problèmes de transport, du manque de services de garde d'enfants, d'horaires de travail ou d'un trop grand nombre de rendez-vous au tribunal.\n",
    "\n",
    "Une solution d’apprentissage automatique peut chercher à réduire les coûts mais en fin de compte faire le contraire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Résumé\n",
    "\n",
    "\n",
    "-  L’utilisation (peut-être bien intentionnée) des algorithmes sans prise de conscience des problèmes conduit à des problèmes d’iniquité.\n",
    "\n",
    "\n",
    "- « Nous n’utilisons pas cette variable » n’est pas un argument.\n",
    "\n",
    "\n",
    "- Il n’existe pas de solution universelle au problème.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Les algorithmes débiaisés/équitables sont difficiles à concevoir, et même leur définition est difficile, nécessitant des connaissances spécialisées dans le domaine et la prise en compte de principes pratiques, éthiques et moraux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Enfin, nous sommes limités par notre accès uniquement à la distribution conjointe $p(X, Y, G...)$. L’inférence causale est une option pour explorer statistiquement ces problèmes plus profonds. Il existe un fossé sémantique difficle à combler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### La semaine prochaine:\n",
    "\n",
    "- Explicabilité de l'apprentissage automatique et perspective causale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merci et je serai heureux de répondre à vos questions !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/merci.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "def finished_lecture(lecture_state: int = 0, thank_you_image_url: str = None):\n",
    "    # Check if the input is an integer and either 0 or 1\n",
    "    if not isinstance(lecture_state, int) or lecture_state not in [0, 1]:\n",
    "        raise ValueError(\"condition must be an integer and either 0 or 1\")\n",
    "\n",
    "    if lecture_state == 1:\n",
    "        print('Merci et je serai heureux de répondre à vos questions !')\n",
    "        display(Image(url='https://raw.githubusercontent.com/matthewvowels1/SIN06023/main/images/merci.png'))\n",
    "    elif lecture_state == 0:\n",
    "        print('Conférence en cours...')\n",
    "        return\n",
    "    \n",
    "    \n",
    "state = 1\n",
    "\n",
    "finished_lecture(lecture_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOZiFt0GEX1EJa/xgMtoCCS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
